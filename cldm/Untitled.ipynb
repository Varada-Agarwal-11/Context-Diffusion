{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969710b0-4721-4624-ab1d-880d37df0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "\n",
    "class ImageLogger(Callback):\n",
    "    def __init__(self, batch_frequency=2000, max_images=4, clamp=True, increase_log_steps=True,\n",
    "                 rescale=True, disabled=False, log_on_batch_idx=False, log_first_step=False,\n",
    "                 log_images_kwargs=None):\n",
    "        super().__init__()\n",
    "        self.rescale = rescale\n",
    "        self.batch_freq = batch_frequency\n",
    "        self.max_images = max_images\n",
    "        if not increase_log_steps:\n",
    "            self.log_steps = [self.batch_freq]\n",
    "        self.clamp = clamp\n",
    "        self.disabled = disabled\n",
    "        self.log_on_batch_idx = log_on_batch_idx\n",
    "        self.log_images_kwargs = log_images_kwargs if log_images_kwargs else {}\n",
    "        self.log_first_step = log_first_step\n",
    "\n",
    "    @rank_zero_only\n",
    "    def log_local(self, save_dir, split, images, prompts, global_step, current_epoch, batch_idx):\n",
    "        root = os.path.join(save_dir, \"image_log\", split)\n",
    "        for k in images:\n",
    "            grid = torchvision.utils.make_grid(images[k], nrow=4)\n",
    "            if self.rescale:\n",
    "                grid = (grid + 1.0) / 2.0  # -1,1 -> 0,1; c,h,w\n",
    "            grid = grid.transpose(0, 1).transpose(1, 2).squeeze(-1)\n",
    "            grid = grid.numpy()\n",
    "            grid = (grid * 255).astype(np.uint8)\n",
    "            filename = \"gs-{:06}_e-{:06}_b-{:06}_{}.png\".format(global_step, current_epoch, batch_idx, k)\n",
    "            path = os.path.join(root, filename)\n",
    "            os.makedirs(os.path.split(path)[0], exist_ok=True)\n",
    "            Image.fromarray(grid).save(path)\n",
    "\n",
    "        filename = \"gs-{:06}_e-{:06}_b-{:06}_prompt.json\".format(global_step, current_epoch, batch_idx)\n",
    "        path = os.path.join(root, filename)\n",
    "        with open(path, \"w\") as f:\n",
    "            for p in prompts:\n",
    "                f.write(f\"{json.dumps(p)}\\n\")\n",
    "\n",
    "    def log_img(self, pl_module, batch, batch_idx, split=\"train\"):\n",
    "        check_idx = batch_idx  # if self.log_on_batch_idx else pl_module.global_step\n",
    "        if (self.check_frequency(check_idx) and  # batch_idx % self.batch_freq == 0\n",
    "                hasattr(pl_module, \"log_images\") and\n",
    "                callable(pl_module.log_images) and\n",
    "                self.max_images > 0):\n",
    "            logger = type(pl_module.logger)\n",
    "\n",
    "            is_train = pl_module.training\n",
    "            if is_train:\n",
    "                pl_module.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)\n",
    "\n",
    "            for k in images:\n",
    "                N = min(images[k].shape[0], self.max_images)\n",
    "                images[k] = images[k][:N]\n",
    "                if isinstance(images[k], torch.Tensor):\n",
    "                    images[k] = images[k].detach().cpu()\n",
    "                    if self.clamp:\n",
    "                        images[k] = torch.clamp(images[k], -1., 1.)\n",
    "\n",
    "            prompts = batch['txt_log'][:self.max_images]\n",
    "\n",
    "            self.log_local(pl_module.logger.save_dir, split, images, prompts,\n",
    "                           pl_module.global_step, pl_module.current_epoch, batch_idx)\n",
    "\n",
    "            if is_train:\n",
    "                pl_module.train()\n",
    "\n",
    "    def check_frequency(self, check_idx):\n",
    "        return check_idx % self.batch_freq == 0\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        if not self.disabled:\n",
    "            self.log_img(pl_module, batch, batch_idx, split=\"train\")\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        if not self.disabled:\n",
    "            self.log_img(pl_module, batch, batch_idx, split=\"val\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a091736-4e1a-4135-9f18-6d9395e31ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
