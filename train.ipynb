{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e219543-62c1-4bd9-9c01-419ae7e9ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging improved.\n"
     ]
    }
   ],
   "source": [
    "from share import *\n",
    "import numpy as np\n",
    "import argparse, os, sys\n",
    "from functools import partial\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from cldm.model import create_model, load_state_dict\n",
    "\n",
    "from ldm.data.base import Txt2ImgIterableBaseDataset\n",
    "from ldm.util import instantiate_from_config\n",
    "\n",
    "\n",
    "def get_parser(**parser_kwargs):\n",
    "\n",
    "    parser = argparse.ArgumentParser(**parser_kwargs)\n",
    "    parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--name\",\n",
    "        type=str,\n",
    "        const=True,\n",
    "        default=\"\",\n",
    "        nargs=\"?\",\n",
    "        help=\"postfix for logdir\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-r\",\n",
    "        \"--resume\",\n",
    "        type=str,\n",
    "        const=True,\n",
    "        default=\"\",\n",
    "        nargs=\"?\",\n",
    "        help=\"resume from logdir or checkpoint in logdir\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-b\",\n",
    "        \"--base\",\n",
    "        type=str,\n",
    "        help=\"paths to base configs. Loaded from left-to-right. \"\n",
    "             \"Parameters can be overwritten or added with command-line options of the form `--key value`.\",\n",
    "        default='./models/cldm_v15.yaml',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-l\",\n",
    "        \"--logdir\",\n",
    "        type=str,\n",
    "        default=\"logs\",\n",
    "        help=\"directory for logging dat shit\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--only_mid_control\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"only_mid_control for control net\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sd_locked\",\n",
    "        action=\"store_false\",\n",
    "        default=True,\n",
    "        help=\"sd_locked for control net\",\n",
    "    )\n",
    "    # Training\n",
    "    parser.add_argument(\n",
    "        \"--gpus\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"number of gpus for training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nnode\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"number of nodes for training\",\n",
    "    )\n",
    "\n",
    "    # Prompt Engineering\n",
    "    parser.add_argument(\n",
    "        \"--data_config\",\n",
    "        type=str,\n",
    "        help=\"path to data config files\",\n",
    "        default='./models/dataset.yaml',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sd_v2\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"if use stable diffusion 2.0\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def worker_init_fn(_):\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "\n",
    "    dataset = worker_info.dataset\n",
    "    worker_id = worker_info.id\n",
    "\n",
    "    if isinstance(dataset, Txt2ImgIterableBaseDataset):\n",
    "        split_size = dataset.num_records // worker_info.num_workers\n",
    "        # reset num_records to the true number to retain reliable length information\n",
    "        dataset.sample_ids = dataset.valid_ids[worker_id * split_size:(worker_id + 1) * split_size]\n",
    "        current_id = np.random.choice(len(np.random.get_state()[1]), 1)\n",
    "        return np.random.seed(np.random.get_state()[1][current_id] + worker_id)\n",
    "    else:\n",
    "        return np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "\n",
    "class DataModuleFromConfig(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, train=None, validation=None, test=None, predict=None,\n",
    "                 num_workers=None, shuffle_test_loader=False, use_worker_init_fn=False,\n",
    "                 shuffle_val_dataloader=False):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_configs = dict()\n",
    "        self.num_workers = num_workers if num_workers is not None else batch_size * 2\n",
    "        self.use_worker_init_fn = use_worker_init_fn\n",
    "        if train is not None:\n",
    "            self.dataset_configs[\"train\"] = train\n",
    "            self.train_dataloader = self._train_dataloader\n",
    "        if validation is not None:\n",
    "            self.dataset_configs[\"validation\"] = validation\n",
    "            self.val_dataloader = partial(self._val_dataloader, shuffle=shuffle_val_dataloader)\n",
    "        if test is not None:\n",
    "            self.dataset_configs[\"test\"] = test\n",
    "            self.test_dataloader = partial(self._test_dataloader, shuffle=shuffle_test_loader)\n",
    "        if predict is not None:\n",
    "            self.dataset_configs[\"predict\"] = predict\n",
    "            self.predict_dataloader = self._predict_dataloader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        for data_cfg in self.dataset_configs.values():\n",
    "            instantiate_from_config(data_cfg)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.datasets = dict(\n",
    "            (k, instantiate_from_config(self.dataset_configs[k]))\n",
    "            for k in self.dataset_configs)\n",
    "\n",
    "    def _train_dataloader(self):\n",
    "        is_iterable_dataset = isinstance(self.datasets['train'], Txt2ImgIterableBaseDataset)\n",
    "        if is_iterable_dataset or self.use_worker_init_fn:\n",
    "            init_fn = worker_init_fn\n",
    "        else:\n",
    "            init_fn = None\n",
    "        return DataLoader(self.datasets[\"train\"], batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers, shuffle=False if is_iterable_dataset else True,\n",
    "                          worker_init_fn=init_fn, persistent_workers=True)\n",
    "\n",
    "    def _val_dataloader(self, shuffle=False):\n",
    "        if isinstance(self.datasets['validation'], Txt2ImgIterableBaseDataset) or self.use_worker_init_fn:\n",
    "            init_fn = worker_init_fn\n",
    "        else:\n",
    "            init_fn = None\n",
    "        return DataLoader(self.datasets[\"validation\"],\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          worker_init_fn=init_fn,\n",
    "                          shuffle=shuffle, persistent_workers=True)\n",
    "\n",
    "    def _test_dataloader(self, shuffle=False):\n",
    "        is_iterable_dataset = isinstance(self.datasets['train'], Txt2ImgIterableBaseDataset)\n",
    "        if is_iterable_dataset or self.use_worker_init_fn:\n",
    "            init_fn = worker_init_fn\n",
    "        else:\n",
    "            init_fn = None\n",
    "\n",
    "        # do not shuffle dataloader for iterable dataset\n",
    "        shuffle = shuffle and (not is_iterable_dataset)\n",
    "\n",
    "        return DataLoader(self.datasets[\"test\"], batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers, worker_init_fn=init_fn, shuffle=shuffle, persistent_workers=True)\n",
    "\n",
    "    def _predict_dataloader(self, shuffle=False):\n",
    "        if isinstance(self.datasets['predict'], Txt2ImgIterableBaseDataset) or self.use_worker_init_fn:\n",
    "            init_fn = worker_init_fn\n",
    "        else:\n",
    "            init_fn = None\n",
    "        return DataLoader(self.datasets[\"predict\"], batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers, worker_init_fn=init_fn, persistent_workers=True)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(os.getcwd())\n",
    "    # parser = get_parser()\n",
    "    # parser = Trainer.add_argparse_args(parser)\n",
    "\n",
    "    opt, _ = get_parser().parse_known_args()\n",
    "\n",
    "    nowname = f\"{opt.name}\"\n",
    "    logdir = os.path.join(opt.logdir, nowname)\n",
    "    ckptdir = os.path.join(logdir, \"checkpoints\")\n",
    "\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    os.makedirs(ckptdir, exist_ok=True)\n",
    "\n",
    "    # Configs\n",
    "    resume_path = './models/control_sd15_ini.ckpt' if not opt.sd_v2 else './models/control_sd21_ini.ckpt'\n",
    "    # batch_size = 32\n",
    "    learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071e7845-fcc5-42d3-b689-20574a092d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python tool_add_control.py \"C:\\\\Desktop\\\\Kanpur\\\\sem 9\\\\tushar sir pgp\\\\Prompt-Diffusion-main\\\\Prompt-Diffusion-main\\\\v1-5-pruned-emaonly.ckpt\" \"./models/control_sd15_ini.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41c6cdc-3d2b-4ec2-a081-b99b6a4682ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "ControlLDM: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Loaded model config from [./models/cldm_v15.yaml]\n",
      "Loaded state_dict from [./models/control_sd15_ini.ckpt]\n"
     ]
    }
   ],
   "source": [
    "    model = create_model(opt.base).cpu()\n",
    "    model.load_state_dict(load_state_dict(resume_path, location='cpu'))\n",
    "    model.learning_rate = learning_rate\n",
    "    model.sd_locked = opt.sd_locked\n",
    "    model.only_mid_control = opt.only_mid_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e17c673-c72f-4d71-9dfe-ca252440e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"diffusers/instructpix2pix-clip-filtered-upscaled\")\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"lansinuote/diffusion.8.instruct_pix2pix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f81981-0e56-478a-aeb9-2fb769936179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python Untitled3.py download shard00.zip and unzip it and seed will be created and then use that to make the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2321a8-0c29-4077-a4c2-19648d5c9e9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (edit_dataset.py, line 96)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[6], line 6\u001b[0m\n    dataloader.prepare_data()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\Desktop\\Kanpur\\sem 9\\tushar sir pgp\\Prompt-Diffusion-main\\Prompt-Diffusion-main\\train.py:136\u001b[0m in \u001b[0;35mprepare_data\u001b[0m\n    instantiate_from_config(data_cfg)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\Desktop\\Kanpur\\sem 9\\tushar sir pgp\\Prompt-Diffusion-main\\Prompt-Diffusion-main\\ldm\\util.py:79\u001b[0m in \u001b[0;35minstantiate_from_config\u001b[0m\n    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()))\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\Desktop\\Kanpur\\sem 9\\tushar sir pgp\\Prompt-Diffusion-main\\Prompt-Diffusion-main\\ldm\\util.py:87\u001b[0m in \u001b[0;35mget_obj_from_str\u001b[0m\n    return getattr(importlib.import_module(module, package=None), cls)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m in \u001b[0;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m in \u001b[0;35m_gcd_import\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m in \u001b[0;35m_find_and_load\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m in \u001b[0;35m_find_and_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m in \u001b[0;35m_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m<frozen importlib._bootstrap_external>:991\u001b[0m in \u001b[0;35mexec_module\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m<frozen importlib._bootstrap_external>:1129\u001b[0m in \u001b[0;35mget_code\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m<frozen importlib._bootstrap_external>:1059\u001b[0m in \u001b[0;35msource_to_code\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[1;36m in \u001b[1;35m_call_with_frames_removed\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Desktop\\Kanpur\\sem 9\\tushar sir pgp\\Prompt-Diffusion-main\\Prompt-Diffusion-main\\edit_dataset.py:96\u001b[1;36m\u001b[0m\n\u001b[1;33m    task = np.random.choice(['inv_seg'])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    #need to download dataset for this cell to run\n",
    "\n",
    "    data_config = OmegaConf.load(opt.data_config)\n",
    "    dataloader = instantiate_from_config(data_config.data)\n",
    "    # dataloader = instantiate_from_config(ds[\"train\"])\n",
    "    dataloader.prepare_data()\n",
    "    dataloader.setup()\n",
    "    print(\"#### Data #####\")\n",
    "    # for k in dataloader.datasets:\n",
    "        # print(f\"{k}, {dataloader.datasets[k].__class__.__name__}, {len(dataloader.datasets[k])}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5756adc-d292-4242-a694-65f4d3ecccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    callbacks_cfg = {\n",
    "        \"checkpoint_callback\": {\n",
    "            \"target\": \"pytorch_lightning.callbacks.ModelCheckpoint\",\n",
    "            \"params\": {\n",
    "                \"dirpath\": ckptdir,\n",
    "                \"filename\": \"{epoch:06}-{step:09}\",\n",
    "                \"verbose\": True,\n",
    "                'save_top_k': -1,\n",
    "                'every_n_train_steps': 1000,\n",
    "                'save_weights_only': True,\n",
    "                \"save_last\": True,\n",
    "            }\n",
    "        },\n",
    "        \"image_logger\": {\n",
    "            \"target\": \"cldm.logger.ImageLogger\",\n",
    "            \"params\": {\n",
    "                \"batch_frequency\": 500,\n",
    "                \"max_images\": 16,\n",
    "                \"clamp\": True,\n",
    "                \"log_images_kwargs\": {'N': 16,\n",
    "                                      'unconditional_guidance_scale': 9.0}\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    callbacks = [instantiate_from_config(callbacks_cfg[k]) for k in callbacks_cfg]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578630a-fa74-46a6-bcf6-43260a394f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # need gpu's for this\n",
    "\n",
    "    tb_logger = pl.loggers.TensorBoardLogger(save_dir=logdir)\n",
    "\n",
    "    # trainer = pl.Trainer(gpus=opt.gpus, accelerator='ddp', num_nodes=opt.nnode,\n",
    "    #                      max_steps=10000, check_val_every_n_epoch=2, accumulate_grad_batches=4,\n",
    "    #                      precision=32, callbacks=callbacks, logger=tb_logger)\n",
    "    trainer = pl.Trainer( num_nodes=opt.nnode,\n",
    "                         max_steps=10000, check_val_every_n_epoch=2, accumulate_grad_batches=4,\n",
    "                         precision=32, callbacks=callbacks, logger=tb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ce773-40c2-444f-be6e-1c6147868366",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #fix small parts of input and download data and get GPU and train model\n",
    "    trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ad51e76-71b8-4e6b-90d3-075a4143285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install eionops\n",
    "# !pip install open_clip_torch\n",
    "# !pip install omegaconf\n",
    "# !pip install pytorch-lightning\n",
    "# !pip install datasets\n",
    "\n",
    "#change in two notebooks from origianl code:\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258c5df-4cf1-455f-a3f2-1289d703c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"lansinuote/diffusion.8.instruct_pix2pix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be18d5-9de7-4ecd-b50b-aeda4ca7ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[\"train\"][\"input\"][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327eb771-308c-4d3c-af43-ca6267dccd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torchvision\n",
    "# from einops import rearrange\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# import pyarrow.parquet as pq\n",
    "# import io\n",
    "# parquet_file_path = 'lansinuote___diffusion.8.instruct_pix2pix/default/0.0.0/f9080eb8f9223440366092de3156757998949cb2//diffusion.8.instruct_pix2pix-train.arrow'\n",
    "# df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "# image_0 = Image.open(io.BytesIO(df['input'][0]))\n",
    "# image_1 = Image.open(io.BytesIO(df['output'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7aae7-605d-48be-aa2b-e7884b5fac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyarrow as pa\n",
    "# import pyarrow.dataset as ds\n",
    "\n",
    "# # Reading the Arrow file directly\n",
    "# dataset = ds.dataset(parquet_file_path)\n",
    "# table = dataset.to_table()\n",
    "# df = table.to_pandas()\n",
    "\n",
    "# # Access the first image from the 'input' column\n",
    "# input_image_data = df['input'][0]  # Adjust the index as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde7f70-e91d-4670-9145-65a3883296d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
